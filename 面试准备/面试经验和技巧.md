### 换工作心得总结

换工作动机：薪资满足 + 精神满足 + 能力发展通道 ==> 物质要求【时薪？工作所得 + 工作付出？】 + 合适的事【好业务？】 + 合适的人【好老板？好同事？好制度】

面试岗位特点：填坑 or 新业务工作

选择哪种工作：喜欢的【增加动机？】 or 擅长的【学习提高？】

面试紧张怎么办? ==> 调整期待【确定非它不可？】；充分准备【自我介绍，项目讲解，技术知识，算法题目】

换工作的时间？==> 关于年初换工作【金三银四】大厂基本上都是4月份应该已经没有多少hc，我们至少在2月份就应该准备完成技术和业务内容。 换工作的时间最好在年前11月份左右。算法题的准备，我觉得有空就得练习下算法题目，而不是等到需要的时候才想到练习。



#### 简历和面试

STAR法则：情境（situation）-  任务（task）-  行动（action） - 结果（result）

简历：基本信息 + 工作履历 + 项目经验 + 专业技能 + 个人评价 【浓缩到2页，项目使用STAR法则】

面试开场白：您好，我是张小侠。2015年毕业于浙江农林大学，信息与计算科学专业。大学毕业后主要有3段工作经历：第一段在网新恒天公司做相关业务开发，这阶段主要是积累技术能力的过程，主要干的工作负责前后端功能代码实现和阿里云服务器运维等工作；一年多后，感觉技术和业务没有成长空间，然后阿里那边有个外包机会，本以为可以接触点核心项目，结果在里面做了一年多功效平台业务。感觉没有前途后，最后就去格家网络干了3年电商核心业务，前面1年半主要做的促销中台业务，主要负责促销优惠模型设计和实现和优惠券和捕手币功能模块。成果就是从0到1搭建了促销系统，满足运营灵活组装优惠活动；后来，老大管理交易部门，把我带了过去，主要负责购物车，交易履约，交易退款和交易结算的相关模块。【讲故事的环节，说明职业规划，说明工作内容，工作结果】

项目面试环节：目标【解决什么问题】 ==> 技术方案【功能模块，技术模块，数据流向】 ==> 项目产出【代码和文档，业务项目指标，可视化】。项目中遇到的挑战点：遗留业务相关技术离职，文档不完善；整理需求点，边看代码边整理文档和单测。快速进行需求开发。协调优惠券服务化改造，成本没法控制管理等...

技术面试环节：技术产生原因 ==> 技术原理【最佳实践 】 ==> 技术局限性 【最好结合自己项目使用】

认识自我优缺点：优点 ==> 有责任心交代给自己的事情能够尽职尽责的完成；热爱技术，有空就研究技术代码，比如看看dubbo和netty源码等；缺点：爱较真，讨论问题喜欢争论输赢，有的事情可能并不是非黑即白。

询问面试官环节：1). 公司使用的技术栈有哪些   2). 团队有哪些业务，目前面试的岗位需要哪些能力。

和Hr谈工资环节：面试前别写期待工资，统一写成面议。根据自己的面试情况和HR进行协商沟通。





####技术面试题

##### Java基础

* Hashmap原理：数组 + 链表 + 红黑树【< 64扩容, >64 && > 8链表转红黑树】；hash值的高低16位取异或
* HashMap为什么不是线程安全的？（多线程操作⽆并发控制，顺便说了在扩容的时候多线程 访问时会造成死锁，会形成⼀个环，不过扩容时多线程操作形成环的问题再JDK1.8已经解决【扩容，不会改变链表顺序】
* 面向对象的3大特性：封装，继承和多态



##### Java多线程

* 线程，进程，协程的区别：进程是操作系统分配资源的最小单位，进程之间是互相独立的。线程是进程划分成的更⼩的运⾏单位,⼀个进程在其执⾏的过程中可以产⽣多个线程，可以共享进程中的内存【比如java堆】；**协程是一种用户态的轻量级线程，**协程的调度完全由用户控制，没有内核切换的开销。
* 多核CPU下，可⻅性怎么保证？==> 总线嗅探技术

* java锁机制：乐观锁 + 悲观锁 + [非]公平锁 + [非]可重入锁【synchronized，ReentrantLock】

* 死锁条件和解决方案：互斥条件 + 请求和保持条件【一次持有多个锁】 + 不可剥夺【超时释放】 + 循环等待【申请资源的顺序】

* AQS实现原理：state + 等待队列 + 多个条件队列。

* volatile实现原理：在指令序列中添加**内存屏障**来禁止指令重排序的【解决可见性和有序性问题】。程序执行是会把主内存中的数据加载到cpu L1,L2缓存中，多线程修改变量，导致主内存和高速缓存数据不一致。内存屏障，保证在读变量从主内存重新加载数据，在写数据时候把高速缓存中的数据写入主内存。

* 线程池原理：先创建核心线程数来处理任务，到达核心线程数后则将任务加入到阻塞队列，如果阻塞队列也满了则创建最大线程数进行处理任务，达到最大线程数并且任务也满了则触发拒接策略。

* 常用并发包：原子类【AtomicXXX】, 并发容器【CopyOnWriteArrayList, ConcurentHashMap, ConcurrentLinkedQueue】，阻塞队列【BlockingQueue】,

  协同工具类【信号量，闭锁，循环屏障】
  
  



##### JVM虚拟机

* 类加载过程：类加载 ==> 验证【验证类的合法性】 ==> 准备【设置常量】 ==> 链接【符号引用转为直接引用】==> 类初始化

* 双亲委派机制：BoostrapClassLoad, ExtClassLoad, AppClassLoad ==> 先委派给父类加载器，父类不能处理则自己处理。

* 垃圾回收算法：复制算法 + 标记清除 + 标记整理

* GC-ROOT有哪些：类对象，虚拟机栈的对象，常量引⽤的对象

* 什么时候需要⾃定义类加载器 ==> 加载特定目录的类，加载加密的网络class文件，热部署加载class文件

* CMS和G1垃圾回收过程：优缺点比较

  CMS：初始标记【GCRoot】==> 并发标记 ==> 预清理 ==> 重新标记 ==> 并发清理 

  G1：初始标记 ==> 并发标记 ==> 最终标记 ==> 清理垃圾



##### SpringBoot

* 作用：自动配置原理，减少复杂的配置，整合常用组件。

* springboot集成包冲突怎么解决：版本总裁

* 说说Spring的⽣命周期吧 ==> 实例化Bean对象；设置Bean的属性；注入Aware的依赖；后置处理器前置方法；初始化方法【afterPropertiesSet, init-method】 ；后置处理器后置方法

* Spring的单例是怎么实现的？ ==> 单例注册表

  



##### Zookeeper

* ZK选举过程：连接领导者超时【Looking状态】 ==> 投票给自己，广播给别人 ==> 接收到投票者信息后，进行领导者pk ==> 选出leader后进行数据同步 ==> 最后节点状态变成广播状态，提供读写服务。
* 脑裂问题：网络分区，导致多个主服务器。==> zk领导者选取和写入过程都是采用过半机制，解决zk脑裂问题。
* zookeeper用作注册中心会有什么问题？ ==> Zookeeper是CP类型服务，当网络发生抖动引起领导者选取的时，整个注册中心会处于不可用状态。



##### MySQL/分库分表

* MySQL实现原理：WAL, redo, undo
* mysql的锁类型：表锁 + metadata lock + 共享锁 + 排他锁 + 间隙锁 + next-key lock
* online ddl实现：新建表结构文件 + 复制原来数据 + 新增事务放到row log中 + 复制完成应用row log【prepare和最终commit会有短暂锁表】
* 隔离级别：读脏 + 读已提交 + 可重复读 + 串行化
* MVCC实现原理：事务版本号 + undo日志
* DDL 小表比较慢的原因：表的事务操作需要获取metadata lock，执行ddl需要获取metadata 写锁，需要等待。
* 主从复制：binlog同步实现，canal
* B树和B+树的区别：B+树是B树的改进版，非叶子节点不存储数据，叶子节点存储所有数据【每层可以容纳更多的子节点，同样的高度B+数据能容纳更多的数据】，并且叶子节点的数据使用双向链表连接，方便遍历【MySQL数据库支持高效范围查找的关键】。
* 分布式事务解决 - 二阶段提交，TCC ，柔性事务【动态生成逆向SQL，无法实现隔离性】，消息队列实现最终一致性
* 分布式ID生成算法：UUID，号段模式，雪花算法【怎么保证ID全局有序？】





##### Redis和缓存

* 数据结构：字符串，集合，列表，排序列表，hash，bitmap, Hyploglog, geo
* 持久化方式：RDB，AOF【优缺点】
* 高可用方案：主从复制，哨兵机制, codis和cluster对比。
* 缓存雪崩，缓存穿透，缓存击穿
* 缓存一致性问题：cache aside, 
* 缓存淘汰策略：LRU,LFU, ROMDOM,  no, volitile-ttl
* 缓存删除策略：定期删除和延迟删除。
* 分布式锁和RedLock：分布式锁的实现





##### 消息队列

* 消息队列作用：异步解耦，流量削峰
* 消息的种类：普通消息 + 顺序消息 + 延时消息【自研】 + 事务消息
* 消息重复消费问题：至少一次投递，消费消息端需要保证接口幂等。
* 顺序消息实现：按照key进行分区，相同key的消息会在同一分区或者队列
* Rocket事务消息实现逻辑：RocketMQ采用了2PC来实现了提交事务消息，先发送事务消息【precommit】,然后执行本地事务【回调Producer的executeLocalTransaction方法】 ==> 业务提交后向Broker反馈Commit 或者Rollback【执行失败时】 ==> 超时会重试调用本地事务
* RocketMQ和Kafka技术选型区别：性能上，Kafka性能要优于RocketMQ, Kafka主要采用Producer端合并多个小消息的方式；高可用方面，RocketMQ的同步刷盘在单机可靠性上比Kafka更高，使用同步刷盘会导致性能下降；功能对比：RocketMQ支持顺序消息，延时消息和事务消息；RocketMQ消费失败支持定时重试；RocketMQ支持根据MessageId查询；RocketMQ支持消息轨迹；RocketMQ支持MessageTag来过滤；





##### 分布式服务

* 分布式和集群区别：应用服务化拆分和集群部署，数据库分库分表-主从，缓存的分片和主从，消息队列的分片和副本。
* 服务改造好处：系统资源扩展性问题【连接池】， 研发效率低下【沟通成本】，部署成本高【编译时间长】
* APM 追踪原理：traceID + spanID【Pinpoint】
* 限流算法【滑动窗口，令牌桶算法，漏桶算法】
* 限流，熔断、降级区别 ==> 熔断是其他系统的保护  ，降级是保护自己 ==>限流也是一种部分流量降级
* 降级，限流设计：【配置中心 - 配置开关，限流规则数据，AOP 代理】
* 压测：设计场景  + 数据准备【根据真实请求模拟数据】 + 性能监控
* 领域驱动设计：共同语言 + 领域边界 + 实体 +   + 聚合 





##### Dubbo框架

* dubbo原理：服务注册和发现 ，集群容错，路由策略，负载均衡，filter链，SPI机制
* 负载均衡：客户端负载均衡和服务端负载均衡，算法：轮询，随机，权重轮询，最小活跃连接
* dubbo延迟暴露的目的：等待系统资源初始化完成。
* 设计RPC框架：服务注册和发现 ， 数据通讯【netty】 ， 数据格式【序列化编码- JDK, Json, Protobuf, Kryo】
* Dubbo的RpcContext是怎么传递的？先在主线程通过ThreadLocal的get⽅法拿到上下⽂信息，在线程池创建新的 ThreadLocal并把之前获取的上下⽂信息设置到ThreadLocal中。这⾥要注意的线程池创建的 ThreadLocal要在finally中⼿动remove，不然会有内存泄漏的问题。
* dubbo使用过程中遇到哪些问题，怎么解决的？==> 线程耗尽【线程隔离】，异常被装换成RuntimeException【自定义异常和接口类放到一个包中】





##### Netty框架

* Netty使用场景：网络传输，网络编程【rpc框架，http，websocket等】
* Netty线程模型：主从reactor【事件驱动模型】，BossGroup对应的线程池处理accept io事件，WorkGroup对应的线程池处理 read, write对应的io事件。我们也可以使用独立的线程池处理业务逻辑。添加handler的时候指定业务线程池。
* Netty半包和粘包解决方案：tcp是面向流传输的。解决方式：固定长度，分隔符，固定长度字段存内容长度信息
* Netty零拷贝方案：CompositeByteBuf 类, 可以将多个 ByteBuf 合并为⼀个逻辑上的 ByteBuf , 避免了各个 ByteBuf 之间的拷⻉；通过 FileRegion 包装的 FileChannel.tranferTo 实现⽂件传输。
* 时间轮算法：数据结构==> 时间刻度 + 任务列表[round圈数倒计时为0的时候进行任务执行] + 分层时间轮。居于堆数据结构的延迟队列，它的时间复杂度是O(logN), 时间轮算法是O(1). 时间推动原理：kafka是启动一个线程进行，从延迟队列中取出最近的一个槽，如果槽的expireTime没到，此操作会阻塞timeoutMs。添加任务/删除任务：根据延迟时间计算出具体任务的槽位，放在该槽位的链表末尾/删除指定任务。

* 多路复用select和 epoll区别：

  > select：使用文件描述符存储连接，应用需要扫描整个感兴趣的事件集合，发现真正活动的事件，连接数过大会影响性能。事件属于条件触发
  >
  > poll：优化使用链表保存文件描述符，没有最大文件描述符数量的限制。其他同select
  >
  > epoll：epoll_create ==> 创建epoll实例，epoll_tcl ==> 注册文件描述符事件【使用红黑树存储事件节点- epitem#rb_node，并建立回调关系；当相应的事件发生时会回调方法，将发生的事件添加到epitem#rdlist双链表】，epoll_wait ==> 等待内核IO事件分发，返回已经发生的事件epitem#rdlist。边缘触发
  >
  > 边缘触发【只有第一次满足条件才会触发】；条件触发【只要满足事件条件不断把事件传递给用户】



##### 系统设计问题

功能性需求 + 非功能性需求【健壮性，扩展性，安全性】

* 秒杀系统设计：秒杀是一个高并发 + 高性能 + 高可用系统。解决手段：数据尽量少 + 请求数尽量少【合并】 + 路径尽量短 + 依赖尽量少【降级】。

  > 动静分离：使用CDN缓存静态化数据  + ajax请求后端动态数据【缓存热点数据】
  >
  > 流量削峰：排队【消息队列】 + 答题 
  >
  > 合并请求：并发读取 + 合并写入
  >
  > 兜底方案：开关降级 + QPS/并发限流

* 短链接设计：hash算法 ==> murmurhash； hash冲突 ==> 给原链接地址加上一段特殊后缀。或者使用【自增ID+62位字符编码】

* 限流，降级服务设计：功能设计和非功能设计。效果：定义注解【指定限流规则和降级规则数据】，使用AOP动态读取配置中心数据【限流规则】

  

  

##### 排查问题和解决问题

* 代码异常：打印异常日志 ==> 通过入参分析代码异常。如果没有打印日志，我们需要选择某台机器使用Archas工具，通过参数分析问题
* 代码逻辑漏洞：代码数据由于考虑不周全，导致数据错乱。如果是刚发布，应该及时回滚。【分析代码业务逻辑，找出漏洞】
* 内存溢出问题：导出堆转储，使用MAT工具通过支配树，分析出内存泄露的地方。
* 性能问题：收集性能指标，报警反应过慢的请求。分析代码IO,使用SQL执行计划找出问题原因。【 批量处理，异步处理】
* 高并发问题处理：压测发现性能瓶颈【cpu, 数据库, 网络】，CPU使用率占用很大 ==> 我们就要增加应用服务器；数据库io性能 ==>对于查询我们需要增加缓存；对于写入问题，我们可以考虑分库分表或者使用消息队列;  网络流量太大 ==>可以使用静态化页面并搭配CDN，动态请求进行限流。
* 你们系统⽬前的瓶颈在哪⾥？DB + IO 

技术难点：海量业务数据存储和查询【分库分表 + 分布式事务处理】，高并发场景【缓存 + 消息队列 + 限流降级】，



